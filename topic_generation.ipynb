{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import bertopic\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "FILE = \"data/communications.csv\"\n",
    "TEXT_COLUMN = \"Text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91327a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649b9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(FILE)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c31bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = re.sub(r'[^\\w]', ' ', text)\n",
    "    words = text.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.col(\"Text\")\n",
    "    .map_elements(preprocess_text, return_dtype=pl.String)\n",
    "    .alias(\"clean_text\")\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ffb8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "doc_matrix = vectorizer.fit_transform(df[\"clean_text\"])\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5e419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topics(n: int, feature_names: list[str], doc_matrix, n_top_words=10) -> list[str]:\n",
    "    lda = LatentDirichletAllocation(n_components=n)\n",
    "    lda.fit(doc_matrix)\n",
    "    topics = []\n",
    "    for idx, topic in enumerate(lda.components_):\n",
    "        topics.append([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e49ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "n_top_words = 10\n",
    "for n in range(5, 31):\n",
    "    topics = generate_topics(n, feature_names, doc_matrix, n_top_words=n_top_words)\n",
    "    rows = [[i + 1] + t for i, t in enumerate(topics)]\n",
    "    columns = [\"topic\"] + [f\"word_{i + 1}\" for i in range(n_top_words)]\n",
    "    topics_df = pl.DataFrame(rows, schema=columns, orient=\"row\")\n",
    "    topics_df.write_csv(f\"output/lda_{n:02}_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc22511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in range(5, 31):\n",
    "    df = pl.read_csv(f\"output/lda_{i:02}_topics.csv\")\n",
    "    dfs.append(df)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_for_row(df: pl.DataFrame, i: int) -> list[str]:\n",
    "    return df.row(i)[1:]\n",
    "\n",
    "get_topic_for_row(dfs[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ad4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "communications_df = pl.read_csv(\"data/communications_preprocessed.csv\")\n",
    "communications_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14570d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "texts = [s.split() for s in communications_df[\"clean_text\"]]\n",
    "gensim_dict = Dictionary(documents=texts)\n",
    "coherence_metrics = []\n",
    "for df in dfs:\n",
    "    topics = [get_topic_for_row(df, i) for i in range(len(df))]\n",
    "    cm = CoherenceModel(topics=topics, texts=texts, dictionary=gensim_dict)\n",
    "    coherence = cm.get_coherence()\n",
    "    coherence_metrics.append(coherence)\n",
    "coherence_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2932a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_df = pl.DataFrame({\"topic\": [i for i in range(5, 31)], \"coherence\": coherence_metrics})\n",
    "coherence_df.write_csv(\"output/topic_coherence_lda.csv\")\n",
    "coherence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c79af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_df.sort(\"coherence\", descending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
